{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bit36fc170516d04460ae12d1efa3e0666b",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms.transforms as T\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "TRAIN_SET_NUM = 49000\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_NUM = 25\n",
    "\n",
    "# 数据预处理\n",
    "transform_normal = T.Compose([\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 数据增强\n",
    "transform_aug = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "# 加载训练集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./', train=True, transform=transform_aug, download=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler.SubsetRandomSampler(range(TRAIN_SET_NUM)))\n",
    "\n",
    "# 加载验证集\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./', train=True, transform=transform_normal, download=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=sampler.SubsetRandomSampler(range(TRAIN_SET_NUM, 50000)))\n",
    "\n",
    "# 加载测试集\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./', train=False, transform=transform_normal, download=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "using device: cuda\n"
    }
   ],
   "source": [
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MobileNet(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layers): Sequential(\n    (0): Block(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Block(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Block(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Block(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): Block(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): Block(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (6): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (7): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (8): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (9): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (10): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (11): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (12): Block(\n      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (linear): Linear(in_features=1024, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, \n",
    "    # by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), \n",
    "           512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)             # [batch_size, 32, 32, 32]\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "net = MobileNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "train_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "# 验证模型在验证集或者测试集上的准确率\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()   # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            scores = model(x)\n",
    "            _,preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 *acc ))\n",
    "        return acc\n",
    "\n",
    "def train_model(model, optimizer, epochs=1, scheduler=None):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - model: A Pytorch Module giving the model to train.\n",
    "    - optimizer: An optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train\n",
    "    Returns: best model\n",
    "    '''\n",
    "    best_model_wts = None\n",
    "    best_acc = 0.0\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        for t,(x,y) in enumerate(train_dataloader):\n",
    "            model.train()   # set model to training mode\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch %d, loss=%.4f' % (e, loss.item()))\n",
    "        acc = check_accuracy(val_dataloader, model)\n",
    "        if acc > best_acc:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_acc = acc\n",
    "    print('best_acc:',best_acc)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0, loss=0.6895\nChecking accuracy on validation set\nGot 839 / 1000 correct (83.90)\nEpoch 1, loss=0.3596\nChecking accuracy on validation set\nGot 855 / 1000 correct (85.50)\nEpoch 2, loss=0.2887\nChecking accuracy on validation set\nGot 862 / 1000 correct (86.20)\nEpoch 3, loss=0.7200\nChecking accuracy on validation set\nGot 852 / 1000 correct (85.20)\nEpoch 4, loss=0.5093\nChecking accuracy on validation set\nGot 859 / 1000 correct (85.90)\nEpoch 5, loss=0.3673\nChecking accuracy on validation set\nGot 866 / 1000 correct (86.60)\nEpoch 6, loss=0.2021\nChecking accuracy on validation set\nGot 858 / 1000 correct (85.80)\nEpoch 7, loss=0.5006\nChecking accuracy on validation set\nGot 862 / 1000 correct (86.20)\nEpoch 8, loss=0.2052\nChecking accuracy on validation set\nGot 854 / 1000 correct (85.40)\nEpoch 9, loss=0.3169\nChecking accuracy on validation set\nGot 858 / 1000 correct (85.80)\nEpoch 10, loss=0.1808\nChecking accuracy on validation set\nGot 864 / 1000 correct (86.40)\nEpoch 11, loss=0.2508\nChecking accuracy on validation set\nGot 867 / 1000 correct (86.70)\nEpoch 12, loss=0.2161\nChecking accuracy on validation set\nGot 870 / 1000 correct (87.00)\nEpoch 13, loss=0.1359\nChecking accuracy on validation set\nGot 862 / 1000 correct (86.20)\nEpoch 14, loss=0.2785\nChecking accuracy on validation set\nGot 869 / 1000 correct (86.90)\nEpoch 15, loss=0.3424\nChecking accuracy on validation set\nGot 871 / 1000 correct (87.10)\nEpoch 16, loss=0.1931\nChecking accuracy on validation set\nGot 881 / 1000 correct (88.10)\nEpoch 17, loss=0.2393\nChecking accuracy on validation set\nGot 883 / 1000 correct (88.30)\nEpoch 18, loss=0.2220\nChecking accuracy on validation set\nGot 883 / 1000 correct (88.30)\nEpoch 19, loss=0.1710\nChecking accuracy on validation set\nGot 887 / 1000 correct (88.70)\nEpoch 20, loss=0.0989\nChecking accuracy on validation set\nGot 886 / 1000 correct (88.60)\nEpoch 21, loss=0.1986\nChecking accuracy on validation set\nGot 887 / 1000 correct (88.70)\nEpoch 22, loss=0.2577\nChecking accuracy on validation set\nGot 885 / 1000 correct (88.50)\nEpoch 23, loss=0.1027\nChecking accuracy on validation set\nGot 884 / 1000 correct (88.40)\nEpoch 24, loss=0.1393\nChecking accuracy on validation set\nGot 890 / 1000 correct (89.00)\nbest_acc: 0.89\n"
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=15,gamma=0.1)\n",
    "\n",
    "best_model = train_model(net, optimizer, epochs=EPOCH_NUM, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Checking accuracy on test set\nGot 8767 / 10000 correct (87.67)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8767"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "check_accuracy(test_dataloader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 87.67"
   ]
  }
 ]
}