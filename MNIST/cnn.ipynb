{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bit36fc170516d04460ae12d1efa3e0666b",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7569,\n           0.2863,  0.9922,  1.0000,  0.5843,  0.1059,  0.9922,  0.8196,\n          -0.6392, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.1922,  0.7020,\n           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n           0.7882, -0.7490, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000,  0.3020,  0.9843,  0.9843,\n           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n           0.9843, -0.5843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -0.7647,  0.9294,  0.9843,  0.9843,\n           0.5922,  0.8588,  0.9843,  0.9843,  0.7020,  0.7569,  0.9843,\n           0.9843, -0.5843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -0.7490,  0.6706,  0.9843,  0.9843,  0.3961,\n          -0.8902,  0.5294,  0.9843,  0.9843, -0.7882,  0.1608,  0.9843,\n           0.9843, -0.5843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -0.3020,  0.9843,  0.9843,  0.0039, -0.9137,\n          -1.0000,  0.5294,  0.9843, -0.1843, -0.9922,  0.1608,  0.9843,\n           0.9843, -0.5843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -0.9843,  0.5922,  0.9843,  0.4667, -0.9608, -1.0000,\n          -0.5529,  0.9686,  0.2549, -0.9922, -0.9529,  0.5686,  0.9843,\n           0.9765, -0.6000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000,  0.0745,  0.9843,  0.9059, -0.9216, -1.0000, -1.0000,\n          -0.5765,  0.0824, -0.8588, -1.0000, -0.7255,  0.9843,  0.9843,\n           0.4745, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000,  0.4824,  0.9843,  0.0039, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9294,\n          -0.1922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.7020,  0.8353,  0.8275, -0.8275, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -0.3804,  0.9765,  0.9843,  0.6157,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.2941,  0.9843,  0.2863, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -0.7725,  0.6471,  0.9843,  0.9843,  0.3333,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.3412,  0.9843,  0.2863, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000,  0.0902,  0.9843,  0.9843,  0.4431, -0.8902,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.3412,  0.9843, -0.1137, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -0.0353,  0.9608,  0.9843,  0.9843, -0.1686, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.3412,  0.9843, -0.6314, -1.0000, -1.0000, -1.0000, -0.9843,\n          -0.6863,  0.7647,  0.9843,  0.9843,  0.3725, -0.9843, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.3412,  0.9843, -0.0902, -1.0000, -1.0000, -0.9765, -0.0431,\n           0.9843,  0.9843,  0.9843,  0.8824, -0.9608, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.3412,  0.9843,  0.2863, -1.0000, -0.9843, -0.0353,  0.9843,\n           0.9843,  0.9843,  0.4980, -0.6157, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n           0.1059,  0.9843,  0.7961,  0.4353,  0.4510,  0.9843,  0.9843,\n           0.9843,  0.8275, -0.5059, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.5765,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n           0.8353, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.9373,  0.5529,  0.9843,  0.9843,  0.9843,  0.9843,  0.7020,\n          -0.7882, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -0.6392,  0.8196,  0.9843,  0.0980, -0.4588, -0.8902,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])\ntorch.Size([32, 1, 28, 28])\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_SIZE = 28 * 28\n",
    "HIDDEN_1_SIZE = 300\n",
    "HIDDEN_2_SIZE = 100\n",
    "OUTPUT_SIZE = 10\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "# 标准化、归一化\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='./data', download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images[0])\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CNN(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=9216, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 24 * 24 , 10)\n",
    "        #self.bn1 = nn.BatchNorm1d(HIDDEN_1_SIZE)\n",
    "        #self.fc2 = nn.Linear(HIDDEN_1_SIZE, HIDDEN_2_SIZE)\n",
    "        #self.bn2 = nn.BatchNorm1d(HIDDEN_2_SIZE)\n",
    "        #self.fc3 = nn.Linear(HIDDEN_2_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 16*24*24)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = CNN().cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# lr 如何设置 momentum\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.02, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.7072],\n        [ 0.0000,  0.0000,  0.0000,  0.3941,  0.0000,  8.2863,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          5.4281,  0.0000],\n        [ 0.0000,  5.4598,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3482,  9.6024,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.8070,  0.0000,  0.0000,\n          7.1407,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.2839,  0.0000,  5.2365,  0.0000,  0.0000,\n         10.5726,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3195,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.1887,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  2.7247,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.5842],\n        [ 0.0000,  6.0920,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          1.8932,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([8, 2, 5, 0, 0, 8, 1, 0, 4, 2, 2, 6, 8, 8, 7, 0, 2, 7, 9, 7, 5, 7, 8, 1,\n        7, 6, 8, 8, 0, 6, 3, 1], device='cuda:0')\noutputs \ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.4875,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.9924,  0.0000,  0.0000,\n          1.4588,  3.8371],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  1.0634],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          9.6887,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3623,  7.3278,  0.0000,\n          0.8074,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.7235,  4.4476],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.7230,  0.1501,  0.0000,\n          3.0888,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  2.3443,  0.0000,  0.0000,  0.0000,  0.0000,\n          2.9976,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.7865],\n        [ 0.0000,  2.1989,  0.0000,  0.0000,  0.0000,  1.4378,  0.0000,  0.0000,\n          7.6323,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          4.4196,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  2.6127],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.6990,  0.0000,  0.0000,\n         13.2465,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  5.4103,  0.0000,  8.1972,  2.0666,  0.0000,\n          0.5137,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.3552,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  5.0264],\n        [ 0.0000,  6.5982,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          4.3907,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  4.5039],\n        [ 0.0000,  6.4877,  0.0000,  1.1985,  0.0000,  0.0000,  0.0000,  0.0000,\n          1.9853,  1.2120],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2349,  0.0000,  0.0000,\n          0.0000,  7.8691],\n        [ 0.0000,  0.0000,  0.0000,  3.2889,  0.0000,  8.8433,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.6368,  0.0000,\n          0.0000,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([0, 6, 7, 7, 5, 2, 2, 8, 6, 9, 5, 8, 7, 8, 7, 8, 7, 0, 0, 8, 5, 4, 9, 1,\n        1, 7, 7, 9, 1, 9, 5, 6], device='cuda:0')\noutputs \ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000, 11.4210,  0.0000,  3.7556,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  7.4115],\n        [ 0.0000,  2.6255,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          7.1155,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1403,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  8.1021,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.8511,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  4.4346,  0.0000, 12.2914,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.3452],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.3626,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  6.9099],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0625],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1248,  0.0000,  0.0000,\n          7.8381,  0.0000],\n        [ 0.0000,  0.0000,  0.0000, 15.2223,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  8.1324],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6744,  8.3942,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          2.0248,  6.3137],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  5.3461,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          3.2553,  0.0000],\n        [ 0.0000,  8.0591,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.3027,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.3847,  0.0000,  1.5925,  0.0000,  0.0000,\n          3.8413,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([0, 7, 2, 7, 3, 0, 9, 8, 0, 1, 5, 7, 7, 4, 6, 0, 4, 9, 4, 0, 8, 3, 9, 4,\n        6, 8, 0, 3, 4, 0, 1, 8], device='cuda:0')\n  0%|          | 0/4 [00:10<?, ?it/s]\ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  1.3264],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  6.5736],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.8099,  0.0000,\n          2.4082,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  9.3956],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.9838,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  1.4413,  0.0000,  7.1258,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.6181,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.5075,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  5.8304],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          3.7532,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.9243,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.2280,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  8.3259,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          1.3067,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.4987,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.2083,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          9.5655,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.8760,  0.0000,  0.0000,\n          1.4178,  0.0000],\n        [ 0.0000, 10.4212,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          2.6066,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.9139,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  2.7931],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.0056,  0.0000,  0.0000,\n          5.9755,  2.2058],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.9161],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.2931,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([0, 4, 2, 9, 6, 9, 6, 5, 0, 2, 0, 0, 5, 6, 9, 8, 6, 2, 4, 0, 6, 1, 4, 6,\n        8, 2, 5, 1, 7, 8, 8, 0], device='cuda:0')\noutputs \ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000, 11.0454,  0.0000,  1.8253,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  3.6948,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.4189,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  3.9342,  0.0000,  1.1781,  0.0000,  0.0000,  0.0000,  0.0000,\n          1.6870,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.8247,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  6.9032,  0.0000,  4.2299,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.5638,  0.0000,  1.7824,  0.0000,  0.0000,\n          0.5813,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  8.0623,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  5.1026],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  5.5504],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.9254,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  9.1612,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5009,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  7.9287],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.9026,  6.5455,  0.0000,\n          0.9389,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.0991,  0.0000,\n          5.2443,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  7.1135,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.8686,  0.0000,  0.0000,\n          2.9976,  1.4265],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000, 10.4006,  0.0000,  0.6569,  0.0000,  0.0000,  0.0000,  0.0000,\n          2.5837,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  6.0600,  0.0000,  9.1092,  0.0000,  0.0000,\n          7.5017,  3.8619],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  5.7562],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.3877,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([2, 3, 1, 4, 2, 1, 2, 7, 5, 3, 5, 3, 0, 9, 7, 9, 6, 0, 6, 6, 9, 6, 8, 3,\n        5, 0, 1, 4, 5, 9, 6, 2], device='cuda:0')\noutputs \ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6373,  8.2624,  0.0000,\n          2.5068,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.8273,  4.8387],\n        [ 0.0000,  0.0000,  0.0000,  1.6413,  0.0000, 11.1304,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2411,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          8.6216,  0.9041],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.8895,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  1.0074,  0.0000, 10.2405,  0.0000,  0.0000,\n          0.0952,  0.0000],\n        [ 0.0000,  7.0236,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          5.1264,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  1.4674],\n        [ 0.0000,  4.9591,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  5.8720,  0.0000, 12.5649,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  4.7448,  0.0000, 11.1145,  0.0000,  0.0000,\n          4.1019,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.0219,  0.0000,  0.0000,\n          4.3269,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  9.1534,  0.0000,  2.9926,  0.0000,  0.0000,\n          1.8522,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1140,  0.0000,  0.0000,\n          3.5698,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         11.2150,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  6.3084],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 11.1584,  0.0000,\n          0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\nlabels \ntensor([4, 0, 6, 9, 5, 6, 8, 6, 2, 5, 1, 2, 8, 4, 2, 1, 5, 2, 5, 2, 5, 7, 3, 8,\n        7, 8, 7, 2, 7, 9, 6, 4], device='cuda:0')\n\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e852da3396a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                         \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCH_NUM)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        #print(images.shape)\n",
    "        outputs = net(images)\n",
    "        print(\"outputs \")\n",
    "        print(outputs)\n",
    "        print(\"labels \")\n",
    "        print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if(i % 250 == 0):\n",
    "            with torch.no_grad():\n",
    "                for test_data in testloader:\n",
    "                    test_images, test_labels = test_data\n",
    "                    test_images = test_images.cuda()\n",
    "                    test_labels = test_labels.cuda()\n",
    "                    test_outputs = net(test_images)\n",
    "                    test_loss = criterion(test_outputs, test_labels)\n",
    "            \n",
    "            train_loss_hist.append(running_loss / 250)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if(i % 1000 == 0):\n",
    "            print('step: %d loss: %.3f' % (i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.text.Text at 0x2499b97d7b8>"
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<matplotlib.figure.Figure at 0x24908abb7b8>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (http://matplotlib.org/) -->\r\n<svg height=\"265pt\" version=\"1.1\" viewBox=\"0 0 389 265\" width=\"389pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 265.69625 \r\nL 389.28125 265.69625 \r\nL 389.28125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 228.14 \r\nL 378.58125 228.14 \r\nL 378.58125 10.7 \r\nL 43.78125 10.7 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m78df1ff059\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-30\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.818182 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.090341\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-35\"/>\r\n      </defs>\r\n      <g transform=\"translate(104.909091 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"157.18125\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-31\"/>\r\n      </defs>\r\n      <g transform=\"translate(150.81875 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"206.272159\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(199.909659 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.363068\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-32\"/>\r\n      </defs>\r\n      <g transform=\"translate(249.000568 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"304.453977\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(298.091477 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"353.544886\" xlink:href=\"#m78df1ff059\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-33\"/>\r\n      </defs>\r\n      <g transform=\"translate(347.182386 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- # mini batch *250 -->\r\n     <defs>\r\n      <path d=\"M 51.125 44 \r\nL 36.921875 44 \r\nL 32.8125 27.6875 \r\nL 47.125 27.6875 \r\nz\r\nM 43.796875 71.78125 \r\nL 38.71875 51.515625 \r\nL 52.984375 51.515625 \r\nL 58.109375 71.78125 \r\nL 65.921875 71.78125 \r\nL 60.890625 51.515625 \r\nL 76.125 51.515625 \r\nL 76.125 44 \r\nL 58.984375 44 \r\nL 54.984375 27.6875 \r\nL 70.515625 27.6875 \r\nL 70.515625 20.21875 \r\nL 53.078125 20.21875 \r\nL 48 0 \r\nL 40.1875 0 \r\nL 45.21875 20.21875 \r\nL 30.90625 20.21875 \r\nL 25.875 0 \r\nL 18.015625 0 \r\nL 23.09375 20.21875 \r\nL 7.71875 20.21875 \r\nL 7.71875 27.6875 \r\nL 24.90625 27.6875 \r\nL 29 44 \r\nL 13.28125 44 \r\nL 13.28125 51.515625 \r\nL 30.90625 51.515625 \r\nL 35.890625 71.78125 \r\nz\r\n\" id=\"DejaVuSans-23\"/>\r\n      <path id=\"DejaVuSans-20\"/>\r\n      <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-6d\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-6e\"/>\r\n      <path d=\"M 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\nM 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-62\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-61\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-74\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-63\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-68\"/>\r\n      <path d=\"M 47.015625 60.890625 \r\nL 29.5 51.421875 \r\nL 47.015625 41.890625 \r\nL 44.1875 37.109375 \r\nL 27.78125 47.015625 \r\nL 27.78125 28.609375 \r\nL 22.21875 28.609375 \r\nL 22.21875 47.015625 \r\nL 5.8125 37.109375 \r\nL 2.984375 41.890625 \r\nL 20.515625 51.421875 \r\nL 2.984375 60.890625 \r\nL 5.8125 65.71875 \r\nL 22.21875 55.8125 \r\nL 22.21875 74.21875 \r\nL 27.78125 74.21875 \r\nL 27.78125 55.8125 \r\nL 44.1875 65.71875 \r\nz\r\n\" id=\"DejaVuSans-2a\"/>\r\n     </defs>\r\n     <g transform=\"translate(165.246875 256.416562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-23\"/>\r\n      <use x=\"83.789062\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"115.576172\" xlink:href=\"#DejaVuSans-6d\"/>\r\n      <use x=\"212.988281\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"240.771484\" xlink:href=\"#DejaVuSans-6e\"/>\r\n      <use x=\"304.150391\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"331.933594\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"363.720703\" xlink:href=\"#DejaVuSans-62\"/>\r\n      <use x=\"427.197266\" xlink:href=\"#DejaVuSans-61\"/>\r\n      <use x=\"488.476562\" xlink:href=\"#DejaVuSans-74\"/>\r\n      <use x=\"527.685547\" xlink:href=\"#DejaVuSans-63\"/>\r\n      <use x=\"582.666016\" xlink:href=\"#DejaVuSans-68\"/>\r\n      <use x=\"646.044922\" xlink:href=\"#DejaVuSans-20\"/>\r\n      <use x=\"677.832031\" xlink:href=\"#DejaVuSans-2a\"/>\r\n      <use x=\"727.832031\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"791.455078\" xlink:href=\"#DejaVuSans-35\"/>\r\n      <use x=\"855.078125\" xlink:href=\"#DejaVuSans-30\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m5512cbe54f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5512cbe54f\" y=\"218.363896\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.0 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-2e\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 222.163114)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5512cbe54f\" y=\"175.950448\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(20.878125 179.749667)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5512cbe54f\" y=\"133.537001\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(20.878125 137.33622)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5512cbe54f\" y=\"91.123554\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.5 -->\r\n      <g transform=\"translate(20.878125 94.922773)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5512cbe54f\" y=\"48.710107\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 2.0 -->\r\n      <g transform=\"translate(20.878125 52.509326)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Loss -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-4c\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-6f\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 130.473906)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-4c\"/>\r\n      <use x=\"55.697266\" xlink:href=\"#DejaVuSans-6f\"/>\r\n      <use x=\"116.878906\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"168.978516\" xlink:href=\"#DejaVuSans-73\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p8efaf15b8d)\" d=\"M 58.999432 217.584167 \r\nL 68.817614 71.232674 \r\nL 78.635795 108.292649 \r\nL 88.453977 111.015539 \r\nL 98.272159 129.787894 \r\nL 108.090341 146.17663 \r\nL 117.908523 148.208165 \r\nL 127.726705 158.90556 \r\nL 137.544886 218.088646 \r\nL 147.363068 170.844247 \r\nL 157.18125 171.614146 \r\nL 166.999432 170.141695 \r\nL 176.817614 170.53768 \r\nL 186.635795 170.31778 \r\nL 196.453977 171.752748 \r\nL 206.272159 179.775867 \r\nL 216.090341 218.256364 \r\nL 225.908523 194.576731 \r\nL 235.726705 193.704933 \r\nL 245.544886 196.262121 \r\nL 255.363068 194.530277 \r\nL 265.18125 194.526963 \r\nL 274.999432 193.834207 \r\nL 284.817614 195.11211 \r\nL 294.635795 218.229207 \r\nL 304.453977 196.293133 \r\nL 314.272159 195.953157 \r\nL 324.090341 195.233195 \r\nL 333.908523 195.925473 \r\nL 343.726705 195.739491 \r\nL 353.544886 194.864664 \r\nL 363.363068 196.267647 \r\n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p8efaf15b8d)\" d=\"M 58.999432 20.583636 \r\nL 68.817614 77.393868 \r\nL 78.635795 122.630811 \r\nL 88.453977 125.207448 \r\nL 98.272159 148.560325 \r\nL 108.090341 162.645964 \r\nL 117.908523 161.105867 \r\nL 127.726705 163.37192 \r\nL 137.544886 174.618324 \r\nL 147.363068 172.518667 \r\nL 157.18125 174.404912 \r\nL 166.999432 173.956165 \r\nL 176.817614 174.128992 \r\nL 186.635795 175.079388 \r\nL 196.453977 170.965521 \r\nL 206.272159 193.28715 \r\nL 216.090341 193.063418 \r\nL 225.908523 193.642647 \r\nL 235.726705 193.867966 \r\nL 245.544886 193.895694 \r\nL 255.363068 193.821696 \r\nL 265.18125 193.384398 \r\nL 274.999432 193.831608 \r\nL 284.817614 193.741031 \r\nL 294.635795 193.822978 \r\nL 304.453977 191.787333 \r\nL 314.272159 188.783505 \r\nL 324.090341 193.600781 \r\nL 333.908523 192.98847 \r\nL 343.726705 193.845373 \r\nL 353.544886 193.774555 \r\nL 363.363068 193.591596 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 228.14 \r\nL 43.78125 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 228.14 \r\nL 378.58125 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 228.14 \r\nL 378.58125 228.14 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 10.7 \r\nL 378.58125 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 367.58125 23.7 \r\nL 371.58125 23.7 \r\nQ 373.58125 23.7 373.58125 21.7 \r\nL 373.58125 17.7 \r\nQ 373.58125 15.7 371.58125 15.7 \r\nL 367.58125 15.7 \r\nQ 365.58125 15.7 365.58125 17.7 \r\nL 365.58125 21.7 \r\nQ 365.58125 23.7 367.58125 23.7 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p8efaf15b8d\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"10.7\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss_hist, color='green')\n",
    "plt.plot(test_loss_hist, color='red')\n",
    "plt.legend('train_loss', 'test_loss')\n",
    "plt.xlabel('# mini batch *250')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "准确率： 0.8929333333333334\n"
    }
   ],
   "source": [
    "# 测试模型\n",
    "\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "print('准确率：', float(correct) / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确率： 0.8929333333333334"
   ]
  }
 ]
}