{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bit36fc170516d04460ae12d1efa3e0666b",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d50a8ee4ef92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MNIST_data/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "    \n",
    "class MNIST_data:\n",
    "    def __init__(self, is_train_dataset, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        if is_train_dataset:\n",
    "            all_data = mnist.train.images\n",
    "            all_labels = mnist.train.labels\n",
    "        else:\n",
    "            all_data = mnist.test.images\n",
    "            all_labels = mnist.test.labels\n",
    "\n",
    "        self._data = np.vstack(all_data)              \n",
    "        self._labels = np.vstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:          \n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is lager than all example\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "train_data = MNIST_data(True, True)\n",
    "test_data = MNIST_data(False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "w = tf.get_variable('w', [x.get_shape()[-1], 10], initializer=tf.random_normal_initializer(0, 1))\n",
    "b = tf.get_variable('b', [10], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "y_ = tf.matmul(x, w) + b\n",
    "p_y = tf.nn.softmax(y_)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - p_y))\n",
    "\n",
    "predict = tf.argmax(y_, 1)\n",
    "predict_one_hot = tf.one_hot(predict, 10, dtype=tf.float32)\n",
    "correct_predict = tf.equal(predict_one_hot, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "\n",
    "with tf.name_scope('train_scope'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "merged_summary_test = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "\n",
    "LOG_DIR = '.'\n",
    "run_label = 'run_mnist_tensorboard'\n",
    "run_dir = os.path.join(LOG_DIR, run_label)\n",
    "\n",
    "if not os.path.exists(run_dir):\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "train_log_dir = os.path.join(run_dir, 'train')\n",
    "test_log_dir = os.path.join(run_dir, 'test')\n",
    "if not os.path.exists(train_log_dir):\n",
    "    os.mkdir(train_log_dir)\n",
    "if not os.path.exists(test_log_dir):\n",
    "    os.mkdir(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[Train] Step: 500, loss: 0.12080, acc: 0.87000\n[Train] Step: 1000, loss: 0.12014, acc: 0.86000\n[Train] Step: 1500, loss: 0.09186, acc: 0.89000\n[Train] Step: 2000, loss: 0.08507, acc: 0.90000\n[Train] Step: 2500, loss: 0.09933, acc: 0.89000\n[Train] Step: 3000, loss: 0.09733, acc: 0.88000\n[Train] Step: 3500, loss: 0.06419, acc: 0.93000\n[Train] Step: 4000, loss: 0.05684, acc: 0.94000\n[Train] Step: 4500, loss: 0.07134, acc: 0.92000\n[Train] Step: 5000, loss: 0.04989, acc: 0.95000\n[Test ] Step: 5000, acc: 0.94090\n[Train] Step: 5500, loss: 0.03583, acc: 0.94000\n[Train] Step: 6000, loss: 0.02289, acc: 0.97000\n[Train] Step: 6500, loss: 0.03897, acc: 0.95000\n[Train] Step: 7000, loss: 0.02754, acc: 0.97000\n[Train] Step: 7500, loss: 0.01948, acc: 0.98000\n[Train] Step: 8000, loss: 0.04289, acc: 0.95000\n[Train] Step: 8500, loss: 0.01539, acc: 0.98000\n[Train] Step: 9000, loss: 0.03988, acc: 0.94000\n[Train] Step: 9500, loss: 0.02174, acc: 0.97000\n[Train] Step: 10000, loss: 0.02413, acc: 0.97000\n[Test ] Step: 10000, acc: 0.96920\n"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 20\n",
    "train_steps = 10000\n",
    "test_steps = 100\n",
    "output_summary_every_steps = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(train_log_dir)\n",
    "    test_writer = tf.summary.FileWriter(test_log_dir)\n",
    "\n",
    "    fixed_test_batch_data, fixed_test_batch_labels = test_data.next_batch(batch_size)\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "\n",
    "        eval_ops = [loss, accuracy, train_op]\n",
    "        should_output_summary = ((i + 1) % output_summary_every_steps == 0)\n",
    "        if should_output_summary:\n",
    "            eval_ops.append(merged_summary)\n",
    "\n",
    "        eval_ops_results = sess.run([loss, accuracy, train_op], feed_dict = {x: batch_data, y: batch_labels})\n",
    "\n",
    "        if should_output_summary:\n",
    "            train_summary_str = eval_ops_results[-1]\n",
    "            train_writer.add_summary(train_summary_str, i+1)\n",
    "            test_summary_str = sess.run([merged_summary_test], feed_dict={x: fixed_test_batch_data, y: fixed_test_batch_labels})[0]\n",
    "            test_writer.add_summary(test_summary_str, i+1)\n",
    "\n",
    "        loss_val, acc_val = eval_ops_results[0:2]\n",
    "\n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \\\n",
    "                % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels \\\n",
    "                    = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                    [accuracy],\n",
    "                    feed_dict = {\n",
    "                        x: test_batch_data, \n",
    "                        y: test_batch_labels\n",
    "                    })\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f' % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9692"
   ]
  }
 ]
}